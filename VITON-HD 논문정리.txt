<VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization>

input image: 1024X768 person image,  target clothing image --> output: 1024 X 768 virtual try-on img.

----
Abstract
----
desired body part에 fusing the warped item.
기존 연구 한계: resolution of synthesized images is still limited to low (e.g., 256x192).
개요:
1. segmentation map을 준비
2. roughly 타겟 옷을 given person's body에 입힌다.
3. ALgnment-Aware Segment(ALIAS) normalization & ALIAS generator 가 misaligned areas를 다루고, input image의 ㅇetail을 보존한다.

효과:
VITON-HD는 synthesized image의 baseline에서 높게 성능이 나타난다. 

----
Intro
----

Img based VITON --> image generation, image synthesis task.
합성된 이미지는 다음의 조건을 만족.
1. person's pose, body, shape, identity 가 보존되어야 해
2. clothing product가 주어진 body shape, pose 에 대해 자연스레 변형되어야 한다.
3. 옷의 Detail이 살아야 해.
4. body parts는 기본적으로 person의 옷에 의해 cocclude된다. 따라서 이부분도 적절히 render해야 해.

이전 연구들의 다음의 두가지 과정을 거친다는 공통점.
1. Warping the clothing image initially to fit the human body
2. FUsing the warped clothing image and the image of the preson that includes pixel-level refinement.

또는 종종, segmentation map을 생성해서 사전에 final image로부터 person's layout을 결정하도록 만드는 방법들도 있다.[9,36,35]

--> 하지만 이 모든 synthetic image들의 resoltuion은 256X192가 보통.

그 이유:
1. misalignment between the warped clothes and aperson's body results  --> image size가 커질수록 noticeable하더라.
2. body에 fit 하도록 옷을 warping하는 것이 어렵다.

ClothFlow[9]는 clothe의 optical flow map을 예측하고 desired clothing region하도록 만들었지만, misalignment 를 완전히 제거하기에는 부족.

그래서 본 논문은 이 문제를 해결하겠다.
by leveragin the pose infrom + segementation map --> the clothing infromation is eliminated thoroughly.
Using the additional infrom(ALIgnment--Aware Segment(ALIAS)) normalization removes infrom irrelevant to the clothing texture in the misaligned regions.. and propagates the semantic infrom throughout the network.
이러한 ALIAS의 normalization이 misaligned region 영역과 다른 영역을 standardize하고, standardized activation을 segemntatino map을 이용해서 modulate한다.

각 feature level마다 multi--scale refinement을 통해서 옷의 디테일을 보존한다.


--
Contribution
--
1. propose a novel image-based virtual try--on approach(VITON-HD) --> synthesize 1024x768 images..
2. introduce a clothing-agnostic person representation --> to remove the dependenc on the clothing item originally worn by the person.
3. address the misalignmnet between the warped clothes and the desired clothing regions by ALIAS normalization & ALIAS generator.
4. demonstrate the superior performance of our method through experiments with baselines on the newly collected dataset.

-----
Related Work
-----

----
Conditional Image Synthesis
----
cGNAS,,pix2pix --> 종종 large spatial deformation에 대해서는 blurry image를 생성함.

----
Normalization Layers
----
external data로 affine param을 추정하는 normalization layer를 conditional normalization layer.라고 한다.
conditional batch norm, adaptive instance norm 은 style transfer가 사용한다.
misalignment mask를 external data로 사용하여서 이 misaligned area와 다른 area(within an instance separately)의 평균과 variance를 구하는 normalization alyer를 우리는 제시한다.
After standardization, we modulate standardized activation maps with affine parameters inferred from human-parsing maps to preserve semantic infromation.

----
Virtual Try-on Approaches.
----
2D image-based approaches와 3D model-based approaches가 있다.
이전의 work들과 다르게 우리는 photo-realistic images at high resolution을 생성할 수 있다.

----
Proposed Method
----
input: reference image I[3XHXW] and clothing image c[동일] --> output: synthetic image I^[동일], pose, body shape of I와 c의 detail을 보존.
(I,c,I^)로 straightforward하게 training하면 좋겠지만 이러한 dataset 제작은 costly.
따라서 우리는 (I, c, I) where the person in the ref image I is already wearing c.를 이용.

하지만 이러한 방법은 test time에 model의 generalization ability(일반화 능력)을 해할 수 있으므로 먼저 clothing-agnostic person representation (that 빼다 the clothing information in I and use it as an input)을 구성하였다.
(입고 있는 옷을 빼서 clothing information을 input으로 주었다는 것))
Clothing-agnostic person representation 은 pose map 과 segmentation map을 사용하여 clothing informatino in I를 빼낸다.
그 이후 segmentation generator가 clothing-agnostic person representation에서 segmentation map을 생성ㅇ한다..
그 후,, defrom c to roughly align it to the human body. 
Lastly, ALIAS norm 이 misleading inform(in misaligned area after deforming c)을 제거하고 ALIAS generator가 misaligned area를 채우고 clothing detail을 보존한다.

----
Clothing-Agnostic Person Representation
----
I already wearing c.
VITON task 가 만족해야 하는 조건
1. original clothing item 은 delete되어야 해.
2. pose와 body shape을 예측하기 위한 sufficient infrom은 유지 해야해.
3. face와 hand같이 보존되어야 하는 영역은 person's identity를 나타내기 때문에 유지해야해.

----
Problems of Exisitng Person Representations
----
person의 shape를 유지하기 위해서 많은 논문들이 coarse body shape mask를 image 합성의 cue로 제공한다.. but fail to reproduce the body parts elaborately(e.g., hadns).
ACGPN의 경우, detailed body shape mask를 input으로 주고 NN이 clothign inform을 버리고 대체되도록 만들었지만,, body shape mask는 clothing item의 shape정보도 같이 담겨 있기 때문에 NN과 body shape mask 둘다 완벽히 clothing inform을 없앨 수 없다.
따라서, OG clothign inform이 완전히 제거되지 않고,, test 단계에서 문제가 되더라.

----
Clothing-Agnostic Person Representation(Pre-Processing)
----
결국 clothing agnostic image를 생성해서 하려고 하는 것은 1.eliminate the shpae of clothing item and 2. preserve the body parts that need to be reproduced.
predict the segmentation map S[H*W], pose map P [3*H*W]
by pre-trained networks[7,3]

L: a set of integers indicating the semantic labels.
S: to remove the clothing region to be replaced and preserve the reset of the image.
P: to remove the arms, but no the hands, as they are difficult to reprocue.
S & P --> generate the clothing-agnostic image I_a, clothing-agnostic segmentation map S_a.
이러한 output은 model이 original clothing infrom을 제거하도록 도와주며, 나머지 영역을 보존하도록 지시한다.

heat map 대신에 quality를 높이기 위해 I_a와 RGB P , S_a를 concatenate하였다.

----
Segmentation Generation
----
G_s: Segmentation Generation, U-Net을 adopt
G_s가 (S_a,P,c) --> mapping s를 배우도록 train.
(OG clothing item inform is completely removed.)
total loss L_s (segmentation generator의 loss) = L_cGAN(conditional adversarial loss between S_^ and S) + 람다(CE)(hypter param corresponding to the 상대적인 중요도 between two losses)L_CE(pixel-wise cross-entropy loss).

----
Clothing Image Deformation
----
target clothing item c를 G_s의 output에 따라 aligned된 것을 deform하기 위해,, CP-VTON의 geometric matching module을 도입했다.
* TPS transformation: Thin plate splines (TPS) are a spline-based technique for data interpolation and smoothing.
* 스플라인은 몇개의 점을 기준으로 부드러운 곡선을 그리는 컴퓨터 그래픽스의 방법입니다.

