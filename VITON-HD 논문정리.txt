<VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization>

input image: 1024X768 person image,  target clothing image --> output: 1024 X 768 virtual try-on img.

----
Abstract
----
desired body part에 fusing the warped item.
기존 연구 한계: resolution of synthesized images is still limited to low (e.g., 256x192).
개요:
1. segmentation map을 준비
2. roughly 타겟 옷을 given person's body에 입힌다.
3. ALgnment-Aware Segment(ALIAS) normalization & ALIAS generator 가 misaligned areas를 다루고, input image의 ㅇetail을 보존한다.

효과:
VITON-HD는 synthesized image의 baseline에서 높게 성능이 나타난다. 

----
Intro
----

Img based VITON --> image generation, image synthesis task.
합성된 이미지는 다음의 조건을 만족.
1. person's pose, body, shape, identity 가 보존되어야 해
2. clothing product가 주어진 body shape, pose 에 대해 자연스레 변형되어야 한다.
3. 옷의 Detail이 살아야 해.
4. body parts는 기본적으로 person의 옷에 의해 cocclude된다. 따라서 이부분도 적절히 render해야 해.

이전 연구들의 다음의 두가지 과정을 거친다는 공통점.
1. Warping the clothing image initially to fit the human body
2. FUsing the warped clothing image and the image of the preson that includes pixel-level refinement.

또는 종종, segmentation map을 생성해서 사전에 final image로부터 person's layout을 결정하도록 만드는 방법들도 있다.[9,36,35]

--> 하지만 이 모든 synthetic image들의 resoltuion은 256X192가 보통.

그 이유:
1. misalignment between the warped clothes and aperson's body results  --> image size가 커질수록 noticeable하더라.
2. body에 fit 하도록 옷을 warping하는 것이 어렵다.

ClothFlow[9]는 clothe의 optical flow map을 예측하고 desired clothing region하도록 만들었지만, misalignment 를 완전히 제거하기에는 부족.

그래서 본 논문은 이 문제를 해결하겠다.
by leveragin the pose infrom + segementation map --> the clothing infromation is eliminated thoroughly.
Using the additional infrom(ALIgnment--Aware Segment(ALIAS)) normalization removes infrom irrelevant to the clothing texture in the misaligned regions.. and propagates the semantic infrom throughout the network.
이러한 ALIAS의 normalization이 misaligned region 영역과 다른 영역을 standardize하고, standardized activation을 segemntatino map을 이용해서 modulate한다.

각 feature level마다 multi--scale refinement을 통해서 옷의 디테일을 보존한다.


--
Contribution
--
1. propose a novel image-based virtual try--on approach(VITON-HD) --> synthesize 1024x768 images..
2. introduce a clothing-agnostic person representation --> to remove the dependenc on the clothing item originally worn by the person.
3. address the misalignmnet between the warped clothes and the desired clothing regions by ALIAS normalization & ALIAS generator.
4. demonstrate the superior performance of our method through experiments with baselines on the newly collected dataset.

-----
Related Work
-----

----
Conditional Image Synthesis
----
cGNAS,,pix2pix --> 종종 large spatial deformation에 대해서는 blurry image를 생성함.

----
Normalization Layers
----
external data로 affine param을 추정하는 normalization layer를 conditional normalization layer.라고 한다.
conditional batch norm, adaptive instance norm 은 style transfer가 사용한다.
misalignment mask를 external data로 사용하여서 이 misaligned area와 다른 area(within an instance separately)의 평균과 variance를 구하는 normalization alyer를 우리는 제시한다.
After standardization, we modulate standardized activation maps with affine parameters inferred from human-parsing maps to preserve semantic infromation.

----
Virtual Try-on Approaches.
----
2D image-based approaches와 3D model-based approaches가 있다.
이전의 work들과 다르게 우리는 photo-realistic images at high resolution을 생성할 수 있다.

----
Proposed Method
----
input: reference image I[3XHXW] and clothing image c[동일] --> output: synthetic image I^[동일], pose, body shape of I와 c의 detail을 보존.
(I,c,I^)로 straightforward하게 training하면 좋겠지만 이러한 dataset 제작은 costly.
따라서 우리는 (I, c, I) where the person in the ref image I is already wearing c.를 이용.

